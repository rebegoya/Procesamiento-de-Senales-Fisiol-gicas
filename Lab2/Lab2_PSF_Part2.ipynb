{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Procesado de Señales Fisiológicas</center>\n",
    "## <center>Lab 2 Parte 2: Electroencefalograma (EEG)</center>\n",
    "### <center>Rebeca Goya Esteban, Óscar Barquero Pérez </center>\n",
    "\n",
    "Actualizado: 5 de marzo de 2025.\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licencia de Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />Este obra está bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">licencia de Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International</a>.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2: Señales reales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta segunda parte de la práctica tiene por objetivo el procesamiento y análisis de señales electroencefalográficas reales. \n",
    "\n",
    "Las señales con las que va a trabajar se registraron con el sistema:\n",
    "\n",
    "- actiCAP Express: Sistema de Electrodos Activos Secos, se trata de un sistema de 32 canales.\n",
    "- actiCHamp: amplificador, bateria y licencias. \n",
    "- BrainVision Recorder: software de adquisición de señales.\n",
    "- BrainVision Analyzer: software que nos permitirá hacer una visualización y procesado previo, además de permitir exportar las señales a formato texto.\n",
    "\n",
    "Para poder trabajar con las señales de EEG es necesario extraerlas de una serie de archivos binarios específicos del fabricante del equipo de adquisición (BrainVision). Cada registro dispone de 3 archivos diferentes:\n",
    "* **Archivo .vhdr:** contiene las diferentes cabeceras necesarias para cargar las señales.\n",
    "* **Archivo .vmrk:** contiene las marcas que se hayan podido introducir en el registro durante la adquisición.\n",
    "* **Archivo .eeg:** contiene el registro completo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración previa\n",
    "\n",
    "Para facilitar el desarrollo de la práctica vamos a utilizar una toolbox de Python denominada [MNE-Python](https://mne.tools/stable/index.html), que permite realizar preprocesado y análisis de diferentes tipos de señales de origen cerebral, como puede ser el propio EEG, y otras como señales de MEG (magnetoencefalografía), sEEG (estereoencefalografía), o ECoG (electrocorticografía).\n",
    "\n",
    "Para instalar este toolbox: `pip install mne`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuestiones iniciales\n",
    "Antes de cargar las señales, **abra con un editor de texto el archivo de cabeceras**, y describa algunos de los **parámetros** que nos van a ser de interés en la práctica, como pueden ser:\n",
    "1. Número de canales.\n",
    "2. Frecuencia de muestreo.\n",
    "3. Resolución.\n",
    "\n",
    "Piense en las siguientes cuestiones:\n",
    "1. ¿Qué tipos de ruidos encontramos en las señales de EEG?\n",
    "2. ¿Qué componentes espectrales están presentes en la actividad cerebral?\n",
    "3. Respecto a los canales registrados, ¿se trata de señales monopolares o bipolares? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1.  Lectura y representación\n",
    "\n",
    "En esta práctica **vamos a utilizar el MNE para realizar la carga directa de los registros** realizados con el software de BrainVision, ya que permite hacerlo de forma directa sin exportarlo previamente a texto. El código para realizar la carga de los registros es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne.io as io_eeg\n",
    "\n",
    "#we are going to read an example eeg which is in the folder EEG_example. The method returns a RAW men object\n",
    "filename = 'XXXX'\n",
    "eeg_object = io_eeg.read_raw_brainvision(filename,preload = True) #the remaining parameters are left as default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable **_eeg_object_** es un objeto que dispone de una serie de métodos y atributos. En el caso de los atributos, los más importantes son:\n",
    "* **ch_names:** Nombres de los canales.\n",
    "* **n_times:** Número de instantes temporales.\n",
    "* **times:** Vector de tiempo.\n",
    "* **info: (dict)** [Información de medidas](https://mne.tools/stable/generated/mne.Info.html#mne.Info). Se trata de una estructura de datos que contiene los diferentes metadatos disponibles en el registro.\n",
    "\n",
    "Respecto a los métodos, el más importante es **get_data()**, que nos permitirá acceder a las señales.\n",
    "\n",
    "Una vez llegados a este punto, realice las siguientes tareas:\n",
    "1. Imprima por pantalla los **nombres de los electrodos**.\n",
    "2. Guarde en una variable (eeg) el **registro completo**. Guarde también el **vector de tiempo (t)** y calcule la **frecuencia de muestreo (fs) a partir del vector _t_**. Analice el tamaño de las matrices generadas.\n",
    "3. **Represente 5 segundos del primer canal**, con el eje X en segundos. Pruebe a visualizar diferentes tramos de 10 segundos de la señal.\n",
    "4. Trate de visualizar **intervalos más anchos y más estrechos de señal**, y **haga zoom sobre el segmento visualizado**.\n",
    "5. **Visualice otro canal** de su interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Print the electrodes' names.\n",
    "print(XXXX)\n",
    "\n",
    "## 2. Store both EEG signals and time vector on different variables, and compute the sampling frequency (fs).\n",
    "eeg = XXXX\n",
    "t = XXXX\n",
    "fs = XXXX\n",
    "print('EEG matrix shape: ', eeg.shape)\n",
    "print('Times vector shape: ', t.shape)\n",
    "print('Sampling rate (fs): %d Hz' %fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 3, 4 and 5. Different plots.\n",
    "plt.figure()\n",
    "ch_0 = XXXX\n",
    "plt.plot(t,ch_0)\n",
    "plt.xlim((40,43))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude (muV)')\n",
    "plt.title('EEG channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede comprobar, las señales son bastante ruidosas. Sin embargo, antes de filtrarlas, gastaremos algo de tiempo revisando los diferentes métodos de estimación espectral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2.  Interpretación de la DEP de una señal de EEG\n",
    "\n",
    "**Calcule y represente** la estimación de la DEP de un canal de EEG utilizando el método de Welch. Después, trate de interpretar dicha estimación, y justifique si la señal de EEG necesita ser filtrada o no (de ser así, ¿qué filtrado aplicaría?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "ch_0 = XXXX  # Let's choose a single EEG channel (the first one, for example).\n",
    "f_welch_eeg, Px_welch_eeg = signal.welch(XXXX, fs=fs, window='hamming', nperseg=512, nfft=1024)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(f_welch_eeg,10*np.log10(Px_welch_eeg))\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.xlim(0,160)\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.title('Welch\\'s method (Original EEG)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3.  Filtrado\n",
    "\n",
    "Las señales que ha visualizado en el ejercicio anterior son **señales \"crudas (raw)\"**, por lo que es necesario realizar algún tipo de pre-procesado previo al análisis, con el objetivo de eliminar ruido. Para ello, además de **numpy**, se va a utilizar el paquete _signal_ de **_scipy_**, ya que contiene un amplio abanico de funciones para procesado de señal. Puede consultar la documentación en la siguiente URL:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/signal.html\n",
    "\n",
    "A continuación, realice los siguientes pasos de pre-procesado:\n",
    "\n",
    "1. **Aplique un filtro adaptado \"notch\" sobre la señal de EEG original para cancelar el ruido de 50 Hz** (puede usar $\\mathcal{signal.iirnotch}$ y $\\mathcal{signal.filtfilt}$), vuelva a representar la señal y compruebe en qué medida se ha eliminado este tipo de ruido. Puede probar en diferentes canales. **¿Por qué aplicamos un filtro a esta frecuencia? ¿Existen casos en los que no se deba filtrar a esa frecuencia?**\n",
    "2. **Aplique un filtro FIR pasobanda entre 0.5 y 40 Hz sobre la señal de EEG original** (puede usar $\\mathcal{signal.firwin}$ y $\\mathcal{signal.filtfilt}$). Aplique este mismo filtrado **sobre la señal filtrada con el notch**, y compare los resultados. **¿Existen diferencias entre las señales? ¿Por qué se escogen estas frecuencias de corte?**\n",
    "3. **Aplique un filtro IIR pasobanda entre 0.5 y 40 Hz sobre la señal de EEG original** (puede usar $\\mathcal{signal.butter}$ y $\\mathcal{signal.filtfilt}$). Aplique este mismo filtrado **sobre la señal filtrada con el notch**, y compare los resultados. **¿Cuáles son las principales diferencias entre las señales filtradas con el filtro IIR y con el filtro FIR?**\n",
    "4. **Represente las respuestas en frecuencia de los filtros diseñados** utilizando $\\mathcal{signal.freqz}$.\n",
    "5. **Calcule y represente** la DEP de un canal de la señal de EEG filtrada (filtro FIR pasobanda). **¿Considera que el ruido se ha eliminado corretamente?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Design and apply a notch filter.\n",
    "f0 = XXXX     # Frequency to be removed from the signal (Hz)\n",
    "Q = 30.0    # Quality factor\n",
    "\n",
    "b_notch, a_notch = signal.iirnotch(XXXX, XXXX, XXXX)   # Create notch filter\n",
    "eeg_notch = signal.filtfilt(XXXX, XXXX, XXXX)   # Apply filter\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t,eeg[0,:])        # Plot first channel (original)\n",
    "plt.plot(t,eeg_notch[0,:])        # Plot first channel (notch-filtered)\n",
    "plt.xlim((50,55))\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude [uV]')\n",
    "plt.legend(('Original EEG','Notch-filtered EEG'))\n",
    "plt.title('Comparison between original EEG and Notch-filtered EEG')\n",
    "\n",
    "## 2. Design and apply a FIR bandpass filter.\n",
    "f_low = XXXX        # Low cutoff frequency\n",
    "f_high = XXXX        # High cutoff frequency\n",
    "numtaps = 64      # Filter length\n",
    "\n",
    "b_bp_FIR=signal.firwin(numtaps, [f_low, f_high], pass_zero=False,fs=fs)     # Create FIR bandpass filter\n",
    "\n",
    "eeg_nt_bandpass_FIR = signal.filtfilt(XXXX, 1, XXXX)        # Apply filter (notch-filtered signals)\n",
    "eeg_orig_bandpass_FIR = signal.filtfilt(XXXX, 1, XXXX)            # Apply filter (original signals)\n",
    "\n",
    "## Plot comparison between signals (FIR-filtered)\n",
    "plt.figure()\n",
    "plt.plot(t,eeg_nt_bandpass_FIR[0,:])     #Plot first channel (after band-pass filtering)\n",
    "plt.plot(t,eeg_orig_bandpass_FIR[0,:])     #Plot first channel (after notch + band-pass filtering)\n",
    "plt.xlim((60,65)),\n",
    "plt.ylim((0.04,0.08)),\n",
    "plt.legend(('BP-filtered EEG','Notch+BP filtered EEG'))\n",
    "plt.title('Comparison between BP-filtered EEG and Notch+BP filtered EEG (FIR)')\n",
    "\n",
    "## 3. Design and apply an IIR bandpass filter.\n",
    "f_low = XXXX      # Low cutoff frequency\n",
    "f_high = XXXX        # High cutoff frequency\n",
    "filter_order = 5       # Filter order\n",
    "\n",
    "b_bp_IIR, a_bp_IIR=signal.butter(filter_order, [f_low, f_high], btype='bandpass',fs=fs)     # Create IIR bandpass filter\n",
    "eeg_nt_bandpass_IIR = signal.filtfilt(XXXX, XXXX, XXXX)        # Apply filter (notch-filtered signals)\n",
    "eeg_orig_bandpass_IIR = signal.filtfilt(XXXX, XXXX, XXXX)            # Apply filter (original signals)\n",
    "\n",
    "## Plot comparison between signals (IIR-filtered)\n",
    "plt.figure()\n",
    "plt.plot(t,eeg_orig_bandpass_IIR[0,:])     #Plot first channel (after band-pass filtering)\n",
    "plt.plot(t,eeg_nt_bandpass_IIR[0,:])     #Plot first channel (after notch + band-pass filtering)\n",
    "plt.xlim((50,55)),\n",
    "\n",
    "plt.legend(('BP-filtered EEG','Notch+BP filtered EEG'))\n",
    "plt.title('Comparison between BP-filtered EEG and Notch+BP filtered EEG (IIR)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Plot frequency response of the filters\n",
    "w_notch, h_notch = signal.freqz(XXXX, XXXX, fs=fs)     # Frequency response of the notch filter\n",
    "w_bp_FIR, h_bp_FIR = signal.freqz(XXXX, fs=fs)                       # Frequency response of the bandpass filter (FIR)\n",
    "w_bp_IIR, h_bp_IIR = signal.freqz(XXXX, XXXX, fs=fs)     # Frequency response of the notch filter\n",
    "\n",
    "plt.figure(figsize=[15,5])\n",
    "ax1 = plt.subplot(131)\n",
    "ax1.set_title('Notch filter frequency response')\n",
    "ax1.plot(w_notch, 20 * np.log10(abs(h_notch)), 'b')\n",
    "ax1.set_xlabel('Frequency [Hz]')\n",
    "ax1.set_ylabel('Amplitude [dB]', color='b')\n",
    "ax2 = ax1.twinx()\n",
    "angles = np.unwrap(np.angle(h_notch))\n",
    "ax2.plot(w_notch, angles, 'g')\n",
    "ax2.set_ylabel('Angle (radians)', color='g')\n",
    "ax2.grid()\n",
    "ax2.axis('tight')\n",
    "plt.xlim((0,100))\n",
    "\n",
    "ax3 = plt.subplot(132)\n",
    "plt.ylim((-150,10))\n",
    "ax3.set_title('Bandpass filter frequency response (FIR)')\n",
    "ax3.plot(w_bp_FIR, 20 * np.log10(abs(h_bp_FIR)), 'b')\n",
    "ax3.set_xlabel('Frequency [Hz]')\n",
    "ax3.set_ylabel('Amplitude [dB]', color='b')\n",
    "ax4 = ax3.twinx()\n",
    "angles = np.unwrap(np.angle(h_bp_FIR))\n",
    "ax4.plot(w_bp_FIR, angles, 'g')\n",
    "ax4.set_ylabel('Angle (radians)', color='g')\n",
    "ax4.grid()\n",
    "ax4.axis('tight')\n",
    "plt.xlim((0,100))\n",
    "\n",
    "ax5 = plt.subplot(133)\n",
    "plt.ylim((-150,10))\n",
    "ax5.set_title('Bandpass filter frequency response (IIR)')\n",
    "ax5.plot(w_bp_IIR, 20 * np.log10(abs(h_bp_IIR)), 'b')\n",
    "ax5.set_xlabel('Frequency [Hz]')\n",
    "ax5.set_ylabel('Amplitude [dB]', color='b')\n",
    "ax6 = ax5.twinx()\n",
    "angles = np.unwrap(np.angle(h_bp_IIR))\n",
    "ax6.plot(w_bp_IIR, angles, 'g')\n",
    "ax6.set_ylabel('Angle (radians)', color='g')\n",
    "ax6.grid()\n",
    "ax6.axis('tight')\n",
    "plt.xlim((0,100))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Plot the PSD of one filtered signal (FIR filtered)\n",
    "f_welch_eeg_filtered, Px_welch_eeg_filtered = signal.welch(XXXX, fs=fs, window='hamming', nperseg=512, nfft=1024)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(f_welch_eeg_filtered,10*np.log10(Px_welch_eeg_filtered))\n",
    "#plt.plot(f_welch_eeg_filtered,Px_welch_eeg_filtered)\n",
    "plt.xlim(0,160)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude (dB)')\n",
    "plt.title('Welch\\'s method (Original EEG)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4. Cálculo de potencia media utilizando la DEP\n",
    "\n",
    "Una forma de evaluar si, en la realización de un experimento de EEG, se produce algún tipo de cambio en la señal resultante, es mediante el cálculo de **parámetros espectrales**.\n",
    "\n",
    "En los registros de EEG realizados en la práctica, se ha realizado el siguiente protocolo:\n",
    "1. Registro de 30 segundos con los ojos abiertos.\n",
    "2. Registro de 30 segundos con los ojos cerrados.\n",
    "\n",
    "Un tipo de ritmo típico que puede aparecer en la señal de EEG con ojos cerrados son las denominadas **ondas alfa**, que abarcan un rango espectral desde 8 hasta 13Hz. Para esta parte de la práctica se pide lo siguiente **(utilizando el registro hecho y filtrado)**:\n",
    "1. **Calcule el Periodograma de Welch de cada segmento** utilizando un canal occipital (señales filtradas con el filtro FIR) y los mismos parámetros que en el Ejercicio 2.\n",
    "2. Utilizando la estimación de la DEP anterior, **calcule la potencia media en cada uno de los segmentos en la banda alfa y el ratio respecto a la potencia media total**, y reflexione sobre los resultados. Para calcular la potencia media, puede utilizar un método de integración numérica, como *scipy.integrate.simpson*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simpson\n",
    "\n",
    "## Select one occipital channel\n",
    "oc_eeg = XXXX  \n",
    "\n",
    "## Compute Welch's Periodogram for each segment \n",
    "##0-30 sg\n",
    "\n",
    "f_welch_eeg, Px_welch_eeg_oc1 =signal.welch(oc_eeg[0:int(30*fs)], fs=fs, window='hamming', nperseg=512, nfft=1024)\n",
    "##30-60 sg\n",
    "_, Px_welch_eeg_oc2 =signal.welch(XXXX, fs=fs, window='hamming', nperseg=512, nfft=1024)\n",
    "\n",
    "## Compute the total power for each segment.\n",
    "idx_delta_total = np.logical_and(f_welch_eeg >= 0.5, f_welch_eeg <= 50)\n",
    "avgp_total_1 = simpson(Px_welch_eeg_oc1[idx_delta_total],f_welch_eeg[idx_delta_total])    # 1st segment\n",
    "avgp_total_2 = simpson(Px_welch_eeg_oc2[idx_delta_total],f_welch_eeg[idx_delta_total])    # 2nd segment\n",
    "## Compute the  power on the alpha band for each segment.\n",
    "f_low_index = (np.abs(f_welch_eeg-8)).argmin()    # Compute the index that corresponds (or is close) to f=8 Hz\n",
    "f_high_index = (np.abs(f_welch_eeg-13)).argmin()  # Compute the index that corresponds (or is close) to f=13 Hz\n",
    "\n",
    "\n",
    "# Average power on the alpha band for the 1st segment.\n",
    "avgp_1 = simpson(Px_welch_eeg_oc1[f_low_index:f_high_index],f_welch_eeg[f_low_index:f_high_index])     \n",
    "r_seg1 = avgp_1/avgp_total_1*100;   # Alpha-band power vs total average power ratio for the 1st segment.\n",
    "\n",
    "avgp_2 = simpson(Px_welch_eeg_oc2[f_low_index:f_high_index],f_welch_eeg[f_low_index:f_high_index])     \n",
    "r_seg2 = avgp_2/avgp_total_2*100;   # Alpha-band power vs total average power ratio for the 1st segment.\n",
    "                                    \n",
    "print('Alpha band power ratio (segment 1): ', r_seg1)\n",
    "print('Alpha band power ratio (segment 2): ', r_seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
